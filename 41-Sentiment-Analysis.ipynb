{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8f7516-57f9-471f-8bd9-b080127a688b",
   "metadata": {},
   "source": [
    "![NVIDIA Logo](images/nvidia.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da992d2-2293-4519-8ebb-5a856db69642",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eb453e-7613-4dc9-9715-087799586a53",
   "metadata": {},
   "source": [
    "In this notebook you will begin work on a sentiment analysis task using a dataset of Amazon reviews by performing a baseline zero-shot analysis on 2 GPT models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f27af-228b-4e0e-b718-8345cb50f511",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acdf224-2849-43af-9265-e33d221b10b7",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e18c9-1f9e-4f67-8ad8-f5082c95b021",
   "metadata": {},
   "source": [
    "By the time you complete this notebook you will be able to:\n",
    "- Be familiar with the Amazon reviews dataset.\n",
    "- Observe zero-shot performance for sentiment analysis on the reviews using GPT43B and GPT8B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e084ec8-042a-456b-bdc9-457739a75344",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f12ce63-7179-405b-86cf-03e49f51f354",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2807cfa5-a29a-4e8b-ac92-063655341429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from llm_utils.nemo_service_models import NemoServiceBaseModel\n",
    "from llm_utils.models import Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b1c11-09be-40f1-aceb-09535d298f0b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c7df4-40ae-40dd-826c-93380de3c175",
   "metadata": {},
   "source": [
    "## List Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "babb9dd1-f059-4397-b4c9-6b3a37263fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt8b: gpt-8b-000\n",
      "gpt20b: gpt20b\n",
      "gpt43b_2: gpt-43b-002\n",
      "gpt43b: gpt-43b-001\n",
      "llama70b_chat: llama-2-70b-chat-hf\n",
      "llama70b: llama-2-70b-hf\n"
     ]
    }
   ],
   "source": [
    "Models.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d25de-1012-4c43-9581-299bfb3aacd8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017a817-edab-4029-abb1-4ed21b094ffb",
   "metadata": {},
   "source": [
    "## Amazon Review Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbe245c-bdfc-4f32-9d32-1f4c6dd72f51",
   "metadata": {},
   "source": [
    "For the sentiment analysis task, we will be working with a public dataset of Amazon customer reviews. The raw reviews file has been provided for you at `data/reviews.txt`. It contains 400,000 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b3bd8c8-97ae-41c4-ba8f-201230d63ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 data/reviews.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/reviews.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e875499-21a0-4b86-9dab-b591bf78bb80",
   "metadata": {},
   "source": [
    "If we look at the first few samples, we can see that each begins with either `__label__2` which indicates a positive sentiment, or `__label__1` which indicates a negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9205db7b-3de0-4a3f-b883-f29367eeb87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__2 Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I'm in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life's hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\"\n",
      "__label__2 One of the best game music soundtracks - for a game I didn't really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren't included I would still consider the collection worth it.\n",
      "__label__1 Batteries died within a year ...: I bought this charger in Jul 2003 and it worked OK for a while. The design is nice and convenient. However, after about a year, the batteries would not hold a charge. Might as well just get alkaline disposables, or look elsewhere for a charger that comes with batteries that have better staying power.\n"
     ]
    }
   ],
   "source": [
    "!head -3 data/reviews.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fa6a99-9d99-43f5-8917-22a7487af193",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba284d1-47e9-444c-943e-d0a1fa7bdfb2",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b0aa57-6039-498a-83f4-53c926ec61d9",
   "metadata": {},
   "source": [
    "For our sentiment analysis task, we will be working with the following prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9eda9dc-abfc-4dd7-99eb-b47274580bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_template(text):\n",
    "    return f'Is the overall sentiment of the following review \"positive\" or \"negative\"? {review} Sentiment:'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90124566-4319-457b-9db6-96f2928fd5e7",
   "metadata": {},
   "source": [
    "Assuming we have a review to pass into the template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b62eeab9-643e-48ed-b49a-60db83da3c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = f'''\\\n",
    "One of the best game music soundtracks - for a game I didn't really play: Despite the fact that I \\\n",
    "have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger \\\n",
    "which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. \\\n",
    "There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially \\\n",
    "like, as there's not too many of those kinds of songs in my other video game soundtracks. \\\n",
    "I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.\\\n",
    "My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, \\\n",
    "which I find distracting. But even if those weren't included I would still consider the collection worth it.\\\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101be73-a2b9-4f58-94ea-c496de9da4d8",
   "metadata": {},
   "source": [
    "...we can generate a sentiment analysis prompt for the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c7823a8-298a-4eea-9e1f-3f082d320430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the overall sentiment of the following review \"positive\" or \"negative\"? One of the best game music soundtracks - for a game I didn't really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren't included I would still consider the collection worth it. Sentiment:\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_template(review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314d9fdc-ade4-4730-b3e5-4040b99738f2",
   "metadata": {},
   "source": [
    "## Process Prompts and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38a5f1a-362b-4edb-ad46-ea79693be749",
   "metadata": {},
   "source": [
    "For our purposes we will create a training dataset of 1500 samples, as well as a small test dataset of 20 samples.\n",
    "\n",
    "Here we gather the first 1520 samples into a `prompts_with_labels` list which contains 2-tuples of review prompts, created using `sentiment_template`, and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e392486e-7124-4152-8c56-3208a9a5e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_with_labels = []\n",
    "\n",
    "with open('data/reviews.txt', 'r', encoding='utf-8') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i >= 1520:  # Stop after reading 1520 lines\n",
    "            break\n",
    "\n",
    "        label, review = line.strip().split(' ', 1)\n",
    "        sentiment = 'positive' if label == '__label__2' else 'negative'\n",
    "        prompts_with_labels.append((sentiment_template(review), sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3d23612-f333-481f-ac34-807cab44739b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Is the overall sentiment of the following review \"positive\" or \"negative\"? Great CD: My lovely Pat has one of the GREAT voices of her generation. I have listened to this CD for YEARS and I still LOVE IT. When I\\'m in a good mood it makes me feel better. A bad mood just evaporates like sugar in the rain. This CD just oozes LIFE. Vocals are jusat STUUNNING and lyrics just kill. One of life\\'s hidden gems. This is a desert isle CD in my book. Why she never made it big is just beyond me. Everytime I play this, no matter black, white, young, old, male, female EVERYBODY says one thing \"Who was that singing ?\" Sentiment:', 'positive')\n"
     ]
    }
   ],
   "source": [
    "print(prompts_with_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b8ec64-a42b-43f1-a2ad-57fc0d077379",
   "metadata": {},
   "source": [
    "Next we split the list into separate train and test lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f22437ed-8124-4e12-94b8-619111b583b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prompts_with_labels = prompts_with_labels[:1500]\n",
    "test_prompts_with_labels = prompts_with_labels[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "739dad1e-495f-46c2-a2b2-4c76f4957f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_prompts_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13b59c07-11f2-4c75-a318-6250ba8d15f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_prompts_with_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5828c-dd80-4672-94d8-f0979a4bb983",
   "metadata": {},
   "source": [
    "## Write Data to File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf1cbc8-a30c-4e75-a3ef-d1d7fb9f661b",
   "metadata": {},
   "source": [
    "For use in subsequent notebooks, we will now write the train and test prompts and labels data to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a845d15-607a-49df-9180-f9484b45abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sentiment_prompts_labels_train_1500.json', 'w') as f:\n",
    "    json.dump(train_prompts_with_labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edecc43e-412b-4b22-a8c0-2e0f3e9b09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/sentiment_prompts_labels_test_20.json', 'w') as f:\n",
    "    json.dump(test_prompts_with_labels, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14beda75-5bf4-45dc-9904-f2b21c92b690",
   "metadata": {},
   "source": [
    "## Test Models on Zero-shot Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252e6a3b-9cd4-4896-acc6-0caa7cfbce88",
   "metadata": {},
   "source": [
    "Before we begin work on fine-tuning, let's establish a baseline for performance by using our zero-shot prompts with GPT43B and GPT8B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259425d7-ee75-4d85-9f43-850dd84e1a40",
   "metadata": {},
   "source": [
    "## GPT43B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400d5669-105a-4c07-922f-fb028c70a787",
   "metadata": {},
   "source": [
    "First we create an instance of the GPT43B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa299557-f32e-4d5c-9d22-49d0fc7c896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt43b = NemoServiceBaseModel(Models.gpt43b.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc279d04-e7b9-4279-8bba-7283faef5936",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837665ae-1012-462d-8b97-27e905a88db1",
   "metadata": {},
   "source": [
    "Let's try a single sentiment analysis prompt out on GPT43B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa289e6e-4cb6-4268-b6a4-26901cdd53ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt, label = test_prompts_with_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a05dab0e-4a30-409d-9b97-bd38cf33ffd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37419306-5b5c-409c-a24f-22aac4a99965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' negative'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt43b.generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c04f4-1491-4854-b6e1-79131402cea8",
   "metadata": {},
   "source": [
    "Except for some white space we can strip, it looks pretty good so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b1ba6c-6d0e-41ef-b5d9-ca9f65481f21",
   "metadata": {},
   "source": [
    "### Try on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e170e08f-e36a-4c56-91bc-cd6b24f3ac2a",
   "metadata": {},
   "source": [
    "Let's try GPT43B on the full test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8108dbd4-bbf8-42d6-8c0b-4641b578f6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: negative\n",
      "Label: negative\n",
      "Is Correct: True\n",
      "\n",
      "Response: Negative\n",
      "Label: negative\n",
      "Is Correct: False\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: negative\n",
      "Label: negative\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: negative\n",
      "Label: negative\n",
      "Is Correct: True\n",
      "\n",
      "Response: negative\n",
      "Label: negative\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: negative\n",
      "Label: negative\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: negative\n",
      "Label: negative\n",
      "Is Correct: True\n",
      "\n",
      "Response: negative\n",
      "Label: negative\n",
      "Is Correct: True\n",
      "\n",
      "Response: negative\n",
      "Label: negative\n",
      "Is Correct: True\n",
      "\n",
      "Number Correct: 19/20\n",
      "Percentage Correct: 95.0%\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_samples = len(test_prompts_with_labels)\n",
    "for prompt, label in test_prompts_with_labels:\n",
    "    response = gpt43b.generate(prompt).strip()\n",
    "    is_correct = response == label\n",
    "    if is_correct:\n",
    "        num_correct += 1\n",
    "    print(f'Response: {response}')\n",
    "    print(f'Label: {label}')\n",
    "    print(f'Is Correct: {response == label}\\n')\n",
    "\n",
    "print(f'Number Correct: {num_correct}/{num_samples}')\n",
    "print(f'Percentage Correct: {num_correct / num_samples*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd323ff8-5600-454f-9308-bc3e0a58e1fd",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8226deb5-fa8a-4147-a879-faffb5340ded",
   "metadata": {},
   "source": [
    "GPT43B seems to be well-suited out of the box for this sentiment analysis task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93abbae1-e8ac-45be-b600-2cb4efd0a60d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87dc008-a1a5-4a15-8c99-1f76179b917e",
   "metadata": {},
   "source": [
    "## GPT8B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b2d97d-f5fb-4423-8d0f-61ac52b49ca9",
   "metadata": {},
   "source": [
    "Next we will try with GPT8B. First we create a model instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7afc71ef-0683-4a9a-b864-104ebad1825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt8b = NemoServiceBaseModel(Models.gpt8b.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47191e65-2169-466f-9ba3-787750d965af",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f614013-5a72-4a56-80b3-8820bc3c26f3",
   "metadata": {},
   "source": [
    "Let's try a single sentiment analysis prompt out on GPT8B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9a9bd8f-afc0-4c02-93c0-686af13819d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt, label = test_prompts_with_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adb737f7-7d97-40e1-8785-1722b86ef9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15d7e912-ad5a-4abc-b53a-a0f1c100132d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Negative\\n\\nReviewer: jennie - favorite favorite favorite favorite favorite - April 27, 2007\\n\\nSubject: Clay Aiken is a disgrace to the North Carolina name I\\'m sorry: I\\'m sorry for everyone out there who actually spent their money on Clay\\'s CD. I\\'m amazed that Clay even made it to the top ten on American Idol. I think that the only people that voted for him were people that thought he was \"cute\". Personally I think he is a disgrace to the North Carolina name. In conclusion, the only reason I give this CD one star is because you can\\'t give a CD zero stars, if I could give it zero stars I would. Sentiment: Negative\\n\\nReviewer: jennie - favorite favorite favorite favorite favorite - April 27, 2007\\n\\nSubject: Clay Aiken is a disgrace to the North Carolina name I\\'m sorry: I\\'m sorry for everyone'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt8b.generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8168f33-2e2b-4775-9ea3-d4f22d30f693",
   "metadata": {},
   "source": [
    "GPT8B gave us a the correct sentiment, but then went on long after we wished."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60752073-3065-462e-815f-2011c973bbf5",
   "metadata": {},
   "source": [
    "### Try on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d00b72-6935-4045-bc2e-9b08b1ba72ae",
   "metadata": {},
   "source": [
    "Let's try GPT8B on the full test set. We will indicate that we wish the model to stop generating after newline characters, strip white space, and lower case its responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28c346b0-bead-43f8-81f4-3b1412e6736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: negative\n",
      "Label: negative\n",
      "Is Correct: True\n",
      "\n",
      "Response: negative\n",
      "Label: negative\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive.\n",
      "Label: positive\n",
      "Is Correct: False\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: negative\n",
      "Is Correct: False\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: negative\n",
      "Label: negative\n",
      "Is Correct: True\n",
      "\n",
      "Response: negative\n",
      "Label: negative\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: negative\n",
      "Label: negative\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive\n",
      "Label: positive\n",
      "Is Correct: True\n",
      "\n",
      "Response: positive.\n",
      "Label: positive\n",
      "Is Correct: False\n",
      "\n",
      "Response: negative\n",
      "Label: negative\n",
      "Is Correct: True\n",
      "\n",
      "Response: negative\n",
      "Label: negative\n",
      "Is Correct: True\n",
      "\n",
      "Response: negative.\n",
      "Label: negative\n",
      "Is Correct: False\n",
      "\n",
      "Number Correct: 16/20\n",
      "Percentage Correct: 80.0%\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_samples = len(test_prompts_with_labels)\n",
    "for prompt, label in test_prompts_with_labels:\n",
    "    response = gpt8b.generate(prompt, stop=['\\n']).strip().lower()\n",
    "    is_correct = response == label\n",
    "    if is_correct:\n",
    "        num_correct += 1\n",
    "    print(f'Response: {response}')\n",
    "    print(f'Label: {label}')\n",
    "    print(f'Is Correct: {response == label}\\n')\n",
    "\n",
    "print(f'Number Correct: {num_correct}/{num_samples}')\n",
    "print(f'Percentage Correct: {num_correct / num_samples*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b098c4-d7d9-4f0b-bda8-2fbfe36c8d36",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f725da-371c-4d70-9aeb-6aa9fa8f13fa",
   "metadata": {},
   "source": [
    "GPT8B did pretty well on this task, although we had to rely on a fair amount of post-processing, including a stop character to prevent it from going on long after we wished.\n",
    "\n",
    "Looking at the outputs above, it missed at least a couple on account of including a period at the end of its output, and we see that it still got the wrong sentiment on occasion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
